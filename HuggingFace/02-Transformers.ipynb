{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoNvdFNVsDHe"
      },
      "source": [
        "# Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-a7Gdl5sDHj"
      },
      "source": [
        "Transformer are involved in all kinds of NLP applications:\n",
        "<ul>\n",
        "<li> Sentiment analysis</li>\n",
        "<li> Zero-shot classification</li>\n",
        "<li> Text generation</li>\n",
        "<li> Mask filling</li>\n",
        "<li> Named entity recognition</li>\n",
        "<li> Question answering</li>\n",
        "<li> Summarization</li>\n",
        "<li> Translation</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ze_DV1IsDHk"
      },
      "source": [
        "Sentiment analysis using the default pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eh_-UY70sU2A"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5-JTDvDsDHl",
        "outputId": "b1d60b8e-6ec3-4b07-d850-0fef8469df68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZoUDkvhuoxi"
      },
      "source": [
        "Providing a list of strings to the classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1W6ygyQuoxk",
        "outputId": "de3dadc2-59b2-462d-94a5-2b80e0f12e23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "classifier([\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH1KHGzsuoxl"
      },
      "source": [
        "Example of translation specifying the model:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses"
      ],
      "metadata": {
        "id": "AK_xH3xovXYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW28AV_Euoxm",
        "outputId": "ea91598b-5763-4768-e99d-5f33180b844c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': '¡Que tengas un buen día!'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
        "translator(\"Have a nice day!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsZf2KPEuoxp"
      },
      "source": [
        "[More examples of NLP applications based on Transformers](https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter1/section3.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Function [pipeline()](https://huggingface.co/docs/transformers/pipeline_tutorial):\n",
        "<ul>\n",
        "* First parameter defines the task\n",
        "* Default parameters are selected, if not specified\n",
        "* There are general and task-specific parameters\n",
        "</ul>\n",
        "* General parameters: model=str, device=n, batch size=n\n",
        "* Model is downloaded and cached when creating classifier object\n",
        "* Three main steps inside pipeline():\n",
        "<ul>\n",
        "* The text is preprocessed into model format\n",
        "* The preprocessed inputs are passed to the model.\n",
        "* Model predictions are post-processed\n",
        "</ul>"
      ],
      "metadata": {
        "id": "TaezXTnzvqkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out [all the pre-trained models available](https://huggingface.co/models)"
      ],
      "metadata": {
        "id": "_W_eJwZYwfcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** Use the [small version of the Whisper model from OpenAI](https://huggingface.co/openai/whisper-small) to recognise [this audio in Spanish](https://huggingface.co/datasets/Narsil/asr_dummy/resolve/285aeb6e0cb9a9dbba1ce9b16a98f0b1655d4884/4.flac) generating as a maximum 30 tokens."
      ],
      "metadata": {
        "id": "JIEJit7nwvJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "generator = pipeline(task=\"automatic-speech-recognition\",model=\"openai/whisper-small\",max_new_tokens=30)\n",
        "generator(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/285aeb6e0cb9a9dbba1ce9b16a98f0b1655d4884/4.flac\")"
      ],
      "metadata": {
        "id": "HoVn7bSdw-gx",
        "outputId": "d25f4ecf-a3bb-4c87-d2ab-fde1c39be88e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ' Y en las ramas medio sumergidas revoloteaban algunos pájaros de quimérico y legendario plumaque.'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}