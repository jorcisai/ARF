{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNohdwBHNx5xDV5amM1Z/wW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizers"
      ],
      "metadata": {
        "id": "ilDzuxzsAkOS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**: In Colab, find pre-trained SentencePiece and Encoder models, such as [mT5](https://huggingface.co/docs/transformers/model_doc/t5#transformers.T5Model), and apply them to the sample sentence ”mT5: A massively multilingual pre-trained text-to-text transformer”. "
      ],
      "metadata": {
        "id": "KXn_1rehFjBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "RRBpFSbEBscn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n",
        "sentence=\"mT5: A massively multilingual pre-trained text-to-text transformer\"\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk7s1L15FstP",
        "outputId": "3e516da3-572c-4d71-c90e-e8e30e8af4e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁m', 'T', '5', ':', '▁A', '▁mass', 'ively', '▁m', 'ultilingual', '▁pre', '-', 't', 'rained', '▁text', '-', 'to', '-', 'text', '▁', 'transformer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRgKrIX3F4Nj",
        "outputId": "d01ebab6-5853-4c56-805d-8d296367dce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[326, 490, 428, 267, 298, 26555, 71403, 326, 182306, 786, 264, 270, 152243, 7461, 264, 476, 264, 1381, 259, 123131]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_string = tokenizer.decode(ids)\n",
        "print(decoded_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL0zYuqAF7Xv",
        "outputId": "9cb78897-7864-4724-a0e5-36e49b8edc7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mT5: A massively multilingual pre-trained text-to-text transformer\n"
          ]
        }
      ]
    }
  ]
}