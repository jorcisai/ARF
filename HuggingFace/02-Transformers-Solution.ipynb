{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoNvdFNVsDHe"
      },
      "source": [
        "# Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIEJit7nwvJV"
      },
      "source": [
        "**Exercise:** Use the [small version of the Whisper model from OpenAI](https://huggingface.co/openai/whisper-small) to recognise [this audio in Spanish](https://huggingface.co/datasets/Narsil/asr_dummy/resolve/285aeb6e0cb9a9dbba1ce9b16a98f0b1655d4884/4.flac) from [this small dataset](https://huggingface.co/datasets/Narsil/asr_dummy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LcpJtnotUY6t"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoVn7bSdw-gx",
        "outputId": "7bd8e5fd-21dd-48d6-e95f-ccbe1cb0e266"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': ' Y en las ramas medio sumergidas revoloteaban algunos pájaros de quimérico y legendario plumaque.'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "transcriber = pipeline(task=\"automatic-speech-recognition\",model=\"openai/whisper-small\")\n",
        "transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/285aeb6e0cb9a9dbba1ce9b16a98f0b1655d4884/4.flac\",generate_kwargs={\"language\": \"spanish\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxfJFB7PdRxW"
      },
      "source": [
        "Alternative solution going into the pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skQnvfjXmBm2"
      },
      "source": [
        "First load [the small dataset](https://huggingface.co/datasets/Narsil/asr_dummy) including four files being the last one, the Spanish audio file referred above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGbk2XBlgkfF",
        "outputId": "71b28c87-263d-49f7-fcd8-20957181538a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    test: Dataset({\n",
            "        features: ['id', 'file'],\n",
            "        num_rows: 4\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "import datasets as ds\n",
        "\n",
        "# load dummy dataset including four audio files\n",
        "dummy_ds = ds.load_dataset(\"Narsil/asr_dummy\")\n",
        "print(dummy_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZUWWwTbF5Ho"
      },
      "source": [
        "Then, downsample it to 16kHz using the [Audio class](https://huggingface.co/docs/datasets/en/package_reference/main_classes#datasets.Audio). You can find [further information on Audio Datasets](https://huggingface.co/blog/audio-datasets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4cRn3ymGByt",
        "outputId": "c9024677-f635-4b79-83bc-3fb33172c0a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': '3', 'file': {'path': '/home/jorcisai/.cache/huggingface/datasets/downloads/b5d16a62fa6856bfbf56c92328e152d4b76a7f1e0f242a9e094ff6821583a329', 'array': array([-2.91038305e-10,  2.32830644e-10,  7.56699592e-10, ...,\n",
            "        1.64538494e-03,  8.10257625e-04,  1.00391894e-03]), 'sampling_rate': 16000}}\n"
          ]
        }
      ],
      "source": [
        "dummy_ds = dummy_ds.cast_column(\"file\", ds.Audio(sampling_rate=16_000))\n",
        "sample = dummy_ds['test'][-1]\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2_IX7XYmK30"
      },
      "source": [
        "Load the [WhisperProcessor](https://huggingface.co/docs/transformers/en/model_doc/whisper#transformers.WhisperProcessor) (audio feature extractor) and the [WhisperForConditionalGeneration](https://huggingface.co/docs/transformers/en/model_doc/whisper#transformers.WhisperForConditionalGeneration) with the language model head. Then, set the prompt into the model configuration to make sure that only transcribes into Spanish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kfoDonvwdeP3"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "# load model and processor\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"spanish\", task=\"transcribe\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdt8myHprdnl"
      },
      "source": [
        "Generate Whisper input vector features from raw audio sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgQWWTUprb18",
        "outputId": "befc0581-c663-4084-bdad-e94fcaf79a70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[-0.6331, -0.6331, -0.6331,  ..., -0.6331, -0.6331, -0.6331],\n",
            "         [-0.6331, -0.6331, -0.6331,  ..., -0.6331, -0.6331, -0.6331],\n",
            "         [-0.6331, -0.6331, -0.6331,  ..., -0.6331, -0.6331, -0.6331],\n",
            "         ...,\n",
            "         [-0.6331, -0.6331, -0.6331,  ..., -0.6331, -0.6331, -0.6331],\n",
            "         [-0.6331, -0.6331, -0.6331,  ..., -0.6331, -0.6331, -0.6331],\n",
            "         [-0.6331, -0.6331, -0.6331,  ..., -0.6331, -0.6331, -0.6331]]])\n"
          ]
        }
      ],
      "source": [
        "input_features = processor(sample[\"file\"][\"array\"], sampling_rate=sample[\"file\"][\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
        "print(input_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFEzERkfsKJY"
      },
      "source": [
        "Inference process calling the [generic generate function](https://huggingface.co/docs/transformers/en/main_classes/text_generation#transformers.GenerationMixin.generate)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apG2RRHqrr0S",
        "outputId": "3d205747-e09f-43b5-c380-dca29b75548f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[50258, 50262, 50359, 50363,   398,   465,  2439, 10211,   296, 22123,\n",
            "          2408, 17025, 11382, 16908,  1370, 18165, 21078, 40639, 10150,   329,\n",
            "           368,   421,   332,   526, 23776,   288,  9451,  4912, 25854, 23179,\n",
            "            13, 50257]])\n"
          ]
        }
      ],
      "source": [
        "predicted_ids = model.generate(input_features)\n",
        "print(predicted_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKyy7vuWtiIZ"
      },
      "source": [
        "Convert ids to words using the function [batch_decode](https://huggingface.co/docs/transformers/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiZgcedpkd6r",
        "outputId": "4f27243e-91ed-4e09-f03e-8c549d68bd2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<|startoftranscript|><|es|><|transcribe|><|notimestamps|> Y en las ramas medio sumergidas revoloteaban algunos pájaros de quimérico y legendario plumaque.<|endoftext|>']\n",
            "[' Y en las ramas medio sumergidas revoloteaban algunos pájaros de quimérico y legendario plumaque.']\n"
          ]
        }
      ],
      "source": [
        "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)\n",
        "print(transcription)\n",
        "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "print(transcription)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
