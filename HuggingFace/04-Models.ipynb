{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcyc9GJhayzs7+KR9p11u7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "OowC-RY98rzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you know, [AutoModel class](https://huggingface.co/transformers/model_doc/auto.html) instantiates any model from a checkpoint. Instead, you could define specific class architecture, such as Bert:"
      ],
      "metadata": {
        "id": "7BqThSS08v_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqHbjmA18R3H"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we work with the well-known [BERT model](https://huggingface.co/docs/transformers/model_doc/bert) available in Hugging Face:"
      ],
      "metadata": {
        "id": "D1GkRbGlXt-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "config = BertConfig()\n",
        "print(config)"
      ],
      "metadata": {
        "id": "wVmNnwO19EEy",
        "outputId": "ff232ef8-0f5d-456e-e1a0-0b995b0ac995",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have the possibility to load a randomly initialized named model architecture to train it from scratch. To this purpose, you first get the configuration of the specific model architecture and then, you create the model from this configuration:"
      ],
      "metadata": {
        "id": "kTAAa6iy_DoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "\n",
        "config = BertConfig()\n",
        "model = BertModel(config)"
      ],
      "metadata": {
        "id": "8B9QDchT_Gjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, you can use the default pre-trained Bert model"
      ],
      "metadata": {
        "id": "TnQZkmZ__TvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "model = BertModel.from_pretrained()"
      ],
      "metadata": {
        "id": "a5gkkJGP_TWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More generally, we can do the same instantiating from the AutoModel class:"
      ],
      "metadata": {
        "id": "N3JS1kUy_fam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "model = AutoModel.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "M3Estlr9_rKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can save pre-trained models in your local directory"
      ],
      "metadata": {
        "id": "aVyWHFOE_y2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\".\")"
      ],
      "metadata": {
        "id": "XxuhM5s4_0HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "2sjbijR2AF-D",
        "outputId": "49c6ecec-39f4-4ee6-d869-da429d6b3dbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json  pytorch_model.bin\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, this writes two files:\n",
        "* config.json: Model attributes and metadata\n",
        "* pytorch model.bin: Model weights"
      ],
      "metadata": {
        "id": "a4UJywJLAAMd"
      }
    }
  ]
}