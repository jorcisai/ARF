{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasTutorial-TrainingAttentionBSLTM.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorcisai/ARF/blob/master/src/KerasTutorial-TrainingAttentionBSLTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWeQAo0Ec_BL"
      },
      "source": [
        "#Bilingual text classifier using own trained word embeddings and Attention + BLSTM layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgZ9gjmPfSnK"
      },
      "source": [
        "## Imports\n",
        "Importing standard packages and tensorflow_datasets to ease data manipulation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baYFZMW_bJHh"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "  \n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DtIDiZkhAaB"
      },
      "source": [
        "Data loading from local file system. Please use the \"traveler\" dataset available in the \"dat\" directory of the GitHub:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uS3QuPcgm92"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  datafn=fn;\n",
        "\n",
        "print(\"Data file: \",datafn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vycakl4thjN2"
      },
      "source": [
        "## Load text data from local file\n",
        "\n",
        "Parsing file line by line to extract class label, source and target sentences. All three are lists of strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L-vKS7Bh-CJ"
      },
      "source": [
        "numsamples=0\n",
        "labs=[]\n",
        "src_sents=[]\n",
        "trg_sents=[]\n",
        "for line in open(datafn):\n",
        "  numsamples+=1\n",
        "  words = line.split(\" \")\n",
        "  labs.append(words[0])\n",
        "  pos=words.index(\"#\")\n",
        "  src_sents.append(\" \".join(words[1:pos-1]))\n",
        "  trg_sents.append(\" \".join(words[pos+1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data preprocessing"
      ],
      "metadata": {
        "id": "xqZAY3HJei2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple conversion from class text label into class integer label:"
      ],
      "metadata": {
        "id": "L0wgdUO9eqE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labset = set()\n",
        "for lab in labs:\n",
        "  labset.add(lab)\n",
        "num_classes=len(labset)\n",
        "\n",
        "lab2id = {}\n",
        "for id,lab in enumerate(labset):\n",
        "  lab2id[lab]=id\n",
        "\n",
        "for id,lab in enumerate(labs):\n",
        "  labs[id]=lab2id[lab]"
      ],
      "metadata": {
        "id": "vOaduHKXersz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization, conversion into sequence of integers and padding:"
      ],
      "metadata": {
        "id": "eoPqiRLEewDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.preprocessing as prepro\n",
        "\n",
        "def tokenize(sents):\n",
        "  tokenizer = prepro.text.Tokenizer(filters='')\n",
        "  tokenizer.fit_on_texts(sents)\n",
        "  tensors = tokenizer.texts_to_sequences(sents)\n",
        "  tensors = prepro.sequence.pad_sequences(tensors,padding='post')\n",
        "\n",
        "  return tensors, tokenizer\n",
        "\n",
        "src_tensors, src_tokenizer = tokenize(src_sents)\n",
        "trg_tensors, trg_tokenizer = tokenize(trg_sents)"
      ],
      "metadata": {
        "id": "J72SZLBUe2O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtZVTyI3nQ5i"
      },
      "source": [
        "Loading class labels, source (Spanish) and target (English) sentences from lists into dataset objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_CsoAaPlz8l"
      },
      "source": [
        "lab_dataset = tf.data.Dataset.from_tensor_slices(labs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0Vu4Ge2pwZa"
      },
      "source": [
        "src_dataset = tf.data.Dataset.from_tensor_slices(src_tensors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yLSKCB0F_Jr"
      },
      "source": [
        "trg_dataset = tf.data.Dataset.from_tensor_slices(trg_tensors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJl1pEUPHoxe"
      },
      "source": [
        "Taking a look at the class labels and source sentences after being converted into dataset type. In this example, the source sentences are used to train the model including word embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPsynLIHICqC"
      },
      "source": [
        "for lab in lab_dataset.take(5):\n",
        "  print(lab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_eCQoF3p70Z"
      },
      "source": [
        "for src in src_dataset.take(5):\n",
        "  print(src)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87aa69dURsRj"
      },
      "source": [
        "for trg in trg_dataset.take(5):\n",
        "  print(trg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out vocabulary sizes:"
      ],
      "metadata": {
        "id": "RLOdn_e3gBb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(src_tokenizer.word_counts))\n",
        "print(len(trg_tokenizer.word_counts))"
      ],
      "metadata": {
        "id": "09bwv_oKgDLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvmTVHBFrovc"
      },
      "source": [
        "First, zipping source and target datasets into a dataset of (source, target) sentences. Then, zipping (source target) dataset with the label dataset, so that we have a ((source, target), label) dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2ErAFTtrUYC"
      },
      "source": [
        "dataset = tf.data.Dataset.zip((tf.data.Dataset.zip((src_dataset, trg_dataset)), lab_dataset)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deiJp8uRMgrm"
      },
      "source": [
        "for sample in dataset.take(5):\n",
        "  print(sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YZToSXSm0qr"
      },
      "source": [
        "## Experimental design\n",
        "\n",
        "Use `tf.data.Dataset.take` and `tf.data.Dataset.skip` to split dataset into 50% for training, 20% for validation and 30% for test.\n",
        "\n",
        "Before being passed into the model, the datasets need to be shuffled and batched. So, first, the complete dataset is shuffled with a fixed seed so that we can repeat the same shuffle of the dataset, then the dataset is split into training, validation and test, and each of these subsets is batched."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-rmbijQh6bf"
      },
      "source": [
        "trainsz = int(numsamples*0.5)\n",
        "valsz= int(numsamples*0.2)\n",
        "testsz= int(numsamples*0.3)\n",
        "batchsz = 100\n",
        "\n",
        "dataset = dataset.shuffle(numsamples,seed=13)\n",
        "\n",
        "train_data = dataset.take(trainsz)\n",
        "train_data = train_data.batch(batchsz)\n",
        "\n",
        "val_data = dataset.skip(trainsz).take(valsz)\n",
        "val_data = val_data.batch(batchsz)\n",
        "\n",
        "test_data = dataset.skip(trainsz+valsz)\n",
        "test_data = test_data.batch(batchsz)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdz7SVwmqi1l"
      },
      "source": [
        "Now, `train_data`, `val_data` and `test_data` are not collections of (`(source, target), label`) pairs, but collections of batches. Each batch is a pair of (*set of (source, target) sentences*, *set of labels*) represented as arrays. To illustrate this idea we take one batch from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMslWfuwoqpB"
      },
      "source": [
        "sample_bitext, sample_label = next(iter(test_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_uTSbUz752e"
      },
      "source": [
        "The sample_bitext is a tuple of (source sentences, target sentences) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yJOc8947kTf"
      },
      "source": [
        "sample_bitext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrmkXp4D8_jC"
      },
      "source": [
        "The 10th source and target sentence of the batch..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_uAc6s47j5e"
      },
      "source": [
        "sample_bitext[0][10], sample_bitext[1][10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C_ouchQ9gFx"
      },
      "source": [
        "... and the corresponding label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHG4Zrff9kds"
      },
      "source": [
        "sample_label[10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8SUhGFNsmRi"
      },
      "source": [
        "## Build the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJzcMswJskw4"
      },
      "source": [
        "First, we define the input layers for the source sentence as an array of integers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meB_9aDktC1Z"
      },
      "source": [
        "src_input = tf.keras.layers.Input(shape=(None,), dtype='int32', name='src_input')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z3xBkeftYiK"
      },
      "source": [
        "The embedding layer converts integer representations to dense vector embeddings. See the [word embeddings tutorial](../text/word_embeddings.ipynb) for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVOoc4M0tn8g"
      },
      "source": [
        "src_vcb_size=len(src_tokenizer.word_counts)\n",
        "src_embed = tf.keras.layers.Embedding(output_dim=16, input_dim=src_vcb_size)(src_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0axBU7gDuRlU"
      },
      "source": [
        "Target sentences undergo the same process as source sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGDQ7tuuu3xn"
      },
      "source": [
        "trg_input = tf.keras.layers.Input(shape=(None,), dtype='int32', name='trg_input')\n",
        "trg_vcb_size=len(trg_tokenizer.word_counts)\n",
        "trg_embed = tf.keras.layers.Embedding(output_dim=16, input_dim=trg_vcb_size)(trg_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention layer in which query is the source sequence embeddings and value is the target sequence embeddings. key is usually the same tensor as value."
      ],
      "metadata": {
        "id": "ApX7pCsRU_Tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_value_attention_seq = tf.keras.layers.Attention()([src_embed, trg_embed])"
      ],
      "metadata": {
        "id": "TzIHEAdeVSVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The query value attention sequence is passed to a bidirectional LSTM"
      ],
      "metadata": {
        "id": "XORRzUlCVxlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense_input = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16))(query_value_attention_seq)"
      ],
      "metadata": {
        "id": "Ot7Ybo15Vr9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gQyku7Kww9r"
      },
      "source": [
        "The output of the bidirectional LSTM is input into a dense feed-forward network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq4Z3QLuwF90"
      },
      "source": [
        "for units in [16,16]:\n",
        "  dense_input = tf.keras.layers.Dense(units, activation='relu')(dense_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsuNznLnxG-N"
      },
      "source": [
        "The output layer produces a probability for all the labels. The one with the highest probability is the models prediction of an example's label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ErESBRxNak"
      },
      "source": [
        "dense_output = tf.keras.layers.Dense(num_classes, activation='softmax')(dense_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYy2Hk-PxWte"
      },
      "source": [
        "Finally, the input and output of the model is defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV1fjarSxb1x"
      },
      "source": [
        "model = tf.keras.models.Model(inputs=[src_input, trg_input], outputs=dense_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slqOsS7ONKlj"
      },
      "source": [
        "Summary of the model to know the number of parameters to be learnt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLg8nyZPNQTg"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLHPU8q5DLi_"
      },
      "source": [
        "Finally, compile the model. For a softmax categorization model, use `sparse_categorical_crossentropy` as the loss function. You can try other optimizers, but `adam` is very common."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkTBUVO4h6Y5"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM-HLo5NDhql"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "This model running on this data produces decent results (99% accuracy on the validation set)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLtO33tNh6V8"
      },
      "source": [
        "history = model.fit(train_data, epochs=10, validation_data=val_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXMdJZMLPxPf"
      },
      "source": [
        "##Evaluate the model\n",
        "\n",
        "Compute accuracy on the test set (almost 99% accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTPCYf_Jh6TH"
      },
      "source": [
        "eval_loss, eval_acc = model.evaluate(test_data)\n",
        "\n",
        "print('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7IWg9UBNUNM"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])\n",
        "  plt.show()\n",
        "  \n",
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
